---
date: '2025-02-17T13:43:41+08:00'
draft: true
title: 'What Intelligence'
math: true
ShowReadingTime: false
ShowWordCount: false
---


妄图想一篇文章梳理下这波人工智能的主线。

语言模型的进展：transformer -> 预训练（GPT系列）-> RL（o1，R1）

* transformer 很强
* imagenet，alexnet 就是 scaling 的实践
* openai 在做语言模型之前就在做rl

智能不只有说话，还需要看懂图





理解生成统一

scaling走到头了


vlm在压缩什么
genai是智能吗：不是，本质是压缩已有数据





## 技术路线

## Reference

- [Jeff Clune's talk in ICLR 2025](https://iclr.cc/virtual/2025/10000096)
- [Ilya Sutskever: Sequence to Sequence Learning with Neural Networks at NeurIPS 2024](https://www.youtube.com/watch?v=WQQdd6qGxNs)
- [OpenAI 研究](https://openai.com/zh-Hans-CN/research/index/)
- [具身智能需要从ImageNet做起吗？](https://zhuanlan.zhihu.com/p/1906157729292219201)
- [张小珺Jùn｜商业访谈录: 和王鹤聊，具身智能的学术边缘史和资本轰炸后的人为乱象](https://www.xiaoyuzhoufm.com/episode/6857f2174abe6e29cb65d76e)
- [张小珺Jùn｜商业访谈录: 机器人遭遇数据荒？与谢晨聊：仿真与合成数据、Meta天价收购和Alexandr Wang](https://www.xiaoyuzhoufm.com/episode/68767e4c93fd2d72b8607c80)